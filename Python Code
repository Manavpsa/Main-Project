import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy import signal
import statistics
import codecs
import serial
import time
import os
import librosa
from PIL import Image
from PyEMD import EMD
from scipy.signal import hilbert
import matplotlib.pyplot as plt
from keras.applications.vgg16 import VGG16,
preprocess input
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Dropout
from keras.models import Model
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load model
************PYSERIAL CODE***********

ser = serial.Serial(’COM5’,9600,timeout = 1)
time.sleep(2)
co=[]
for i in range(2000):
line = ser.readline()
s=codecs.decode(line)
content=s.strip(”  ̊ ”)
print(content)
co.append(float(content))
ser.close()
num=[]
for item in co
num.append(float(item))
signal1=num[1000:2000]
signal1=np.array(signal1)

***************LUNG SOUND REMOVAL (WAVELET TRANSFORM)***********

fs, data = wav.read(”104 1b1 Al sc Litt3200.wav”)
data=data[::6]
if len(data.shape) > 1:
data = data[:, 0]
wavelet = ’db4’
level = 4
coeffs = pywt.wavedec(data, wavelet, level=level)
reconstructed signal = pywt.waverec(coeffs, wavelet)
plt.figure()
plt.plot(data, label=’Original signal’)
plt.plot(reconstructed signal, label=’Reconstructed signal’)
plt.legend()
plt.show()
reconstructed signal2=reconstructed signal[0:1000]
sample entropy = sampen(reconstructed signal2)
print(”Sample entropy:”, sample entropy)

***************LUNG SOUND REMOVAL (EMD)***********

emd = EMD()
imfs = emd(signal1)
envelopes = []
for i in range(len(imfs)):
analytic signal = hilbert(imfs[i])
amplitude envelope = np.abs(analytic signal)
envelopes.append(amplitude envelope)
heart envelope = envelopes[2]
lung signal = signal1 - heart envelope

**************PLOTTING SPECTROGRAM***********

fig, ax = plt.subplots()
plt.specgram(lung signal,Fs=1764,cmap=’inferno’)
plt.xlabel(’Time (s)’)
plt.ylabel(’Frequency (Hz)’)
plt.colorbar()
plt.gca().set axis off()
plt.subplots adjust(top = 1, bottom = 0, right = 1, left = 0,
hspace = 0, wspace = 0)
plt.margins(0,0)
ax.xaxis.set major locator(plt.NullLocator())
ax.yaxis.set major locator(plt.NullLocator())
plt.savefig(’temp.png’, bbox inches=’tight’, pad inches=0)
image = Image.open(’temp.png’)
image resized = image.resize((224, 224))
************SAVING THE IMAGE****************

output dir = ”F:/MAIN PROJECT/spectrograms/REALTIME”
print(”Enter your name =”)
filename=input()
output filename = os.path.join(output dir,
os.path.splitext(filename)[0] + ”.png”)
image resized.save(output filename)
plt.close()
os.remove(’temp.png’)

****************VGG 16 MODEL*****************
* Define image and model parameters
model = load model(’lung sound classification model.h5’)
img size = (224, 224)
batch size = 32
num classes = 4
labels = [’crackles’, ’wheezes’, ’healthy’, ’both crackles and wheezes’]

* Predict the class of a single image
image path =output filename
img = Image.open(image path).resize(img size)
img = img.convert(’RGB’)
x = np.array(img).astype(np.float32)
x = np.expand dims(x, axis=0)
x = preprocess input(x)

preds = model.predict(x)[0]
class idx = np.argmax(preds)
class name = labels[class idx]
accuracy = preds[class idx]

print(f’The patient has ”class name” with accuracy
accuracy*100:.2f%’)

**********RESNET 18 MODEL**********

* Load the model
resnet = models.resnet18(pretrained=False)
num ftrs = resnet.fc.in features
num classes = 4
resnet.fc = nn.Linear(num ftrs, num classes)
resnet.load state dict(torch.load(’resnet model.pt’))
resnet.eval()
Define the transforms
transform = transforms.Compose([
transforms.Resize(224),
transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
* Define the class labels
class labels = [’both’, ’crackles’, ’healthy’, ’wheezes’]

* Load and preprocess the image to classify
image path = output filename
image = Image.open(image path).convert(’RGB’)
image = transform(image).unsqueeze(0)

* Predict the class of the image
with torch.no grad():
outputs = resnet(image)
, predicted = torch.max(outputs.data, 1)

* Map the predicted class index to its corresponding class name
predicted class = class labels[predicted]
print(”Predicted class:”, predicted class)
import os
import numpy as np
from keras.applications.vgg16 import VGG16,
preprocess input
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Dropout
from keras.models import Model
from PIL import Image
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load model
* Define image and model parameters
img size = (224, 224)
batch size = 32
num classes = 4
labels = [’crackles’, ’wheezes’, ’healthy’, ’both’]

* Load the pre-trained VGG16 model without the top layers
model = VGG16(weights=’imagenet’,
include top=False, input shape=(img size[0], img size[1], 3))

* Freeze the pre-trained layers
for layer in model.layers:
layer.trainable = False

* Add new layers on top of the pre-trained layers
x = model.output
x = Flatten()(x)
x = Dense(512, activation=’relu’)(x)
x = Dropout(0.5)(x)
predictions = Dense(num classes, activation=’softmax’)(x)
model = Model(inputs=model.input,
outputs=predictions)
* Compile the model with appropriate optimizer and loss function
model.compile(optimizer=’adam’, loss=’categorical crossentropy’, metrics=[’accuracy’])

* Create data generators for train and test data
train datagen = ImageDataGenerator(preprocessing function=preprocess input)
train generator = train datagen.flow from directory(
”F:PROJECT”, target size=img size, batch size=batch size, class mode=’categorical’, shuffle=True )

* Train the model with the train generator
model.fit generator(
train generator,
epochs=10,
)
* Save the trained model for future use
model.save(’lung sound classification model.h5’)
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

* Define the ResNet model
resnet = models.resnet18(pretrained=True)
num ftrs = resnet.fc.in features
num classes = 4
resnet.fc = nn.Linear(num ftrs, num classes)

* Define the transforms transform = transforms.Compose([ transforms.Resize(224), transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

* Load the dataset
dataset = datasets.ImageFolder(”F:/MAIN
PROJECT/spectrograms/SPECS”, transform=transform)
* Split the dataset into train and test sets
train size = int(0.8 * len(dataset))
test size = len(dataset) - train size
train dataset, test dataset = torch.utils.data.random split(dataset, [train size, test size])

* Define the dataloaders
train loader = torch.utils.data.DataLoader(train dataset, batch size=32, shuffle=True)
test loader = torch.utils.data.DataLoader(test dataset,
batch size=32, shuffle=False)

* Set device
device = torch.device(”cuda” if torch.cuda.is available() else ”cpu”)

* Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)

* Train the model
num epochs = 10
for epoch in range(num epochs):
running loss = 0.0
for i, (inputs, labels) in enumerate(train loader):
inputs = inputs.to(device)
labels = labels.to(device)
optimizer.zero grad()
outputs = resnet(inputs)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()
running loss += loss.item()
if i % 100 == 99: print(’[%d, %5d] loss: %.3f’ % (epoch + 1, i + 1, running loss / 100))
running loss = 0.0
*Evaluate the model on the test set
correct = 0
total = 0
with torch.no grad():
for inputs, labels in test loader:
inputs = inputs.to(device)
labels = labels.to(device)
outputs = resnet(inputs)
, predicted = torch.max(outputs.data, 1)
total += labels.size(0)
correct += (predicted == labels).sum().item()
print(’Accuracy on the test set: %d %%’ % (100 * correct / total))

* Save the model
torch.save(resnet.state dict(), ’resnet model.pt’)
